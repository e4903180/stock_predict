{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = 'postprocess.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join(os.path.dirname(os.path.abspath(__file__)),'..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from data.loadData import LoadData\n",
    "from data.preprocess import Preprocess\n",
    "from model.fft import Fft\n",
    "from model.lstm import Lstm\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  9.38079178   8.43322849   7.11709265 ...   9.68853424  10.02246679\n",
      "     9.91836946]\n",
      "  [  9.38079178   8.43322849   7.11709265 ...   9.68853424  10.02246679\n",
      "     9.91836946]\n",
      "  [  9.38079178   8.43322849   7.11709265 ...   9.68853424  10.02246679\n",
      "     9.91836946]\n",
      "  ...\n",
      "  [  9.38079178   8.43322849   7.11709265 ...   9.68853424  10.02246679\n",
      "     9.91836946]\n",
      "  [  9.38079178   8.43322849   7.11709265 ...   9.68853424  10.02246679\n",
      "     9.91836946]\n",
      "  [  9.38079178   8.43322849   7.11709265 ...   9.68853424  10.02246679\n",
      "     9.91836946]]\n",
      "\n",
      " [[-40.68542609 -45.49623033 -48.31863098 ... -16.80112665 -26.01734141\n",
      "   -34.0964735 ]\n",
      "  [-40.68542609 -45.49623033 -48.31863098 ... -16.80112665 -26.01734141\n",
      "   -34.0964735 ]\n",
      "  [-40.68542609 -45.49623033 -48.31863098 ... -16.80112665 -26.01734141\n",
      "   -34.0964735 ]\n",
      "  ...\n",
      "  [-40.68542609 -45.49623033 -48.31863098 ... -16.80112665 -26.01734141\n",
      "   -34.0964735 ]\n",
      "  [-40.68542609 -45.49623033 -48.31863098 ... -16.80112665 -26.01734141\n",
      "   -34.0964735 ]\n",
      "  [-40.68542609 -45.49623033 -48.31863098 ... -16.80112665 -26.01734141\n",
      "   -34.0964735 ]]\n",
      "\n",
      " [[ -8.72258036 -11.34563795 -13.47283672 ...   0.89777638  -2.46411062\n",
      "    -5.71830416]\n",
      "  [ -8.72258036 -11.34563795 -13.47283672 ...   0.89777638  -2.46411062\n",
      "    -5.71830416]\n",
      "  [ -8.72258036 -11.34563795 -13.47283672 ...   0.89777638  -2.46411062\n",
      "    -5.71830416]\n",
      "  ...\n",
      "  [ -8.72258036 -11.34563795 -13.47283672 ...   0.89777638  -2.46411062\n",
      "    -5.71830416]\n",
      "  [ -8.72258036 -11.34563795 -13.47283672 ...   0.89777638  -2.46411062\n",
      "    -5.71830416]\n",
      "  [ -8.72258036 -11.34563795 -13.47283672 ...   0.89777638  -2.46411062\n",
      "    -5.71830416]]]\n",
      "(3, 30, 30)\n",
      "[[[  9.38079178   8.43322849   7.11709265 ...   9.68853424  10.02246679\n",
      "     9.91836946]\n",
      "  [  9.38079178   8.43322849   7.11709265 ...   9.68853424  10.02246679\n",
      "     9.91836946]\n",
      "  [  9.38079178   8.43322849   7.11709265 ...   9.68853424  10.02246679\n",
      "     9.91836946]\n",
      "  ...\n",
      "  [  9.38079178   8.43322849   7.11709265 ...   9.68853424  10.02246679\n",
      "     9.91836946]\n",
      "  [  9.38079178   8.43322849   7.11709265 ...   9.68853424  10.02246679\n",
      "     9.91836946]\n",
      "  [  9.38079178   8.43322849   7.11709265 ...   9.68853424  10.02246679\n",
      "     9.91836946]]\n",
      "\n",
      " [[-40.68542609 -45.49623033 -48.31863098 ... -16.80112665 -26.01734141\n",
      "   -34.0964735 ]\n",
      "  [-40.68542609 -45.49623033 -48.31863098 ... -16.80112665 -26.01734141\n",
      "   -34.0964735 ]\n",
      "  [-40.68542609 -45.49623033 -48.31863098 ... -16.80112665 -26.01734141\n",
      "   -34.0964735 ]\n",
      "  ...\n",
      "  [-40.68542609 -45.49623033 -48.31863098 ... -16.80112665 -26.01734141\n",
      "   -34.0964735 ]\n",
      "  [-40.68542609 -45.49623033 -48.31863098 ... -16.80112665 -26.01734141\n",
      "   -34.0964735 ]\n",
      "  [-40.68542609 -45.49623033 -48.31863098 ... -16.80112665 -26.01734141\n",
      "   -34.0964735 ]]\n",
      "\n",
      " [[ -8.72258036 -11.34563795 -13.47283672 ...   0.89777638  -2.46411062\n",
      "    -5.71830416]\n",
      "  [ -8.72258036 -11.34563795 -13.47283672 ...   0.89777638  -2.46411062\n",
      "    -5.71830416]\n",
      "  [ -8.72258036 -11.34563795 -13.47283672 ...   0.89777638  -2.46411062\n",
      "    -5.71830416]\n",
      "  ...\n",
      "  [ -8.72258036 -11.34563795 -13.47283672 ...   0.89777638  -2.46411062\n",
      "    -5.71830416]\n",
      "  [ -8.72258036 -11.34563795 -13.47283672 ...   0.89777638  -2.46411062\n",
      "    -5.71830416]\n",
      "  [ -8.72258036 -11.34563795 -13.47283672 ...   0.89777638  -2.46411062\n",
      "    -5.71830416]]]\n",
      "(3, 30, 30)\n"
     ]
    }
   ],
   "source": [
    "stock_name = \"^GSPC\"\n",
    "date_predict_start = '2020-01-01'\n",
    "window_length = 30\n",
    "slide_range = 40\n",
    "total_windows = 3\n",
    "slide = 5\n",
    "n_harm_lower_limit = 1\n",
    "n_harm_upper_limit = 30\n",
    "dataloader = LoadData(total_windows, window_length)\n",
    "train_data, test_data =\\\n",
    "    dataloader.load_and_split_data(stock_name, date_predict_start, window_length, slide_range, total_windows)\n",
    "x_length = 5\n",
    "y_length = 5\n",
    "# preprocesser = Preprocess()\n",
    "# x_train, y_train =\\\n",
    "#     preprocesser.preprocess_data(train_data, x_length, y_length)\n",
    "model = Fft()\n",
    "mixed_train_harm, mixed_test_harm = model.fft(train_data, window_length, n_harm_lower_limit, n_harm_upper_limit)\n",
    "\n",
    "# harmonics = model.data_to_harmonics_function(train_data, window_length)\n",
    "# processed_signal = model.mix_harmonics_function(harmonics, n_harm_lower_limit, n_harm_upper_limit)\n",
    "print(mixed_train_harm)\n",
    "print(mixed_train_harm.shape)\n",
    "print(mixed_test_harm)\n",
    "print(mixed_test_harm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesser = Preprocess()\n",
    "x_train, y_train, scaler =\\\n",
    "    preprocesser.preprocess_train_data(train_data, x_length, y_length)\n",
    "x_test, y_test, scaler =\\\n",
    "    preprocesser.preprocess_test_data(train_data, test_data, x_length, y_length, slide)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2609 - val_loss: 0.6691\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2524 - val_loss: 0.6720\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2432 - val_loss: 0.6752\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2404 - val_loss: 0.6787\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2326 - val_loss: 0.6824\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2196 - val_loss: 0.6867\n",
      "Epoch 6: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:12<00:24, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.5666 - val_loss: 0.4298\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5330 - val_loss: 0.4168\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5082 - val_loss: 0.4049\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4776 - val_loss: 0.3937\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4341 - val_loss: 0.3848\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3828 - val_loss: 0.3821\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.3584 - val_loss: 0.3929\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.2706 - val_loss: 0.4316\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2160 - val_loss: 0.5270\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1372 - val_loss: 0.7245\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1121 - val_loss: 1.0672\n",
      "Epoch 11: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:22<00:10, 10.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.2555 - val_loss: 0.5966\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2499 - val_loss: 0.5741\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2439 - val_loss: 0.5493\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2397 - val_loss: 0.5218\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2338 - val_loss: 0.4903\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2279 - val_loss: 0.4538\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2136 - val_loss: 0.4111\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2062 - val_loss: 0.3620\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1888 - val_loss: 0.3059\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1834 - val_loss: 0.2437\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1644 - val_loss: 0.1801\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1411 - val_loss: 0.1249\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1301 - val_loss: 0.0976\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1187 - val_loss: 0.1325\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.1108 - val_loss: 0.2419\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1038 - val_loss: 0.3481\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1139 - val_loss: 0.3863\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1170 - val_loss: 0.3489\n",
      "Epoch 18: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:32<00:00, 10.70s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:01<00:02,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 5.93396388e-02  5.88113293e-02  7.16113225e-02  5.97876012e-02\n",
      "    5.61520793e-02]\n",
      "  [-1.45673648e-01 -1.52190015e-01 -1.55315623e-01 -1.41322136e-01\n",
      "   -1.00079715e-01]\n",
      "  [-9.27459002e-02 -9.95671451e-02 -9.74146798e-02 -8.97676945e-02\n",
      "   -6.01333827e-02]\n",
      "  [-1.56896152e-02 -1.99010596e-02 -1.19772591e-02 -1.40511086e-02\n",
      "   -1.51070300e-03]\n",
      "  [-9.73015800e-02 -1.03447504e-01 -1.02239788e-01 -9.40113813e-02\n",
      "   -6.36526272e-02]\n",
      "  [-1.12465665e-01 -1.22193120e-01 -1.19840443e-01 -1.09643556e-01\n",
      "   -7.44794384e-02]]\n",
      "\n",
      " [[ 1.45614669e-01  1.99084207e-01  2.30809271e-01  1.88537300e-01\n",
      "    1.51531085e-01]\n",
      "  [ 8.40958714e-01  1.02426147e+00  1.18602216e+00  1.02516615e+00\n",
      "    8.10379326e-01]\n",
      "  [ 3.30868006e-01  4.22388703e-01  4.86254513e-01  4.01238620e-01\n",
      "    3.28181863e-01]\n",
      "  [-1.16042271e-01 -1.33559436e-01 -1.46491900e-01 -1.14240646e-01\n",
      "   -1.08906403e-01]\n",
      "  [-1.64149597e-01 -1.97974354e-01 -2.19071865e-01 -1.71437800e-01\n",
      "   -1.58726871e-01]\n",
      "  [ 5.12691140e-02  8.17161798e-02  9.58612561e-02  8.00608546e-02\n",
      "    5.89615367e-02]]\n",
      "\n",
      " [[ 7.69416809e-01  7.18016446e-01  1.18852150e+00  1.54170072e+00\n",
      "    1.66876876e+00]\n",
      "  [-1.80126697e-01 -7.29554668e-02 -1.15143918e-01 -1.28523812e-01\n",
      "   -1.74239784e-01]\n",
      "  [-2.29087174e-01 -1.17867172e-01 -1.90120116e-01 -2.27297768e-01\n",
      "   -2.81405568e-01]\n",
      "  [-2.71269739e-01 -1.49645120e-01 -2.45175987e-01 -2.97837108e-01\n",
      "   -3.60089332e-01]\n",
      "  [-4.41743992e-04  7.51536936e-02  1.24594234e-01  1.79674700e-01\n",
      "    1.68777123e-01]\n",
      "  [ 3.52021724e-01  3.76662970e-01  6.05463326e-01  7.95965910e-01\n",
      "    8.52877378e-01]]]\n",
      "(3, 6, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Lstm()\n",
    "lstm_processed_signal = model.lstm(x_train, y_train, x_test, y_test, train_data, test_data, y_length)\n",
    "\n",
    "print(lstm_processed_signal)\n",
    "print(lstm_processed_signal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 6, 5, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_data_pv_function(self, data, pv_range, window_length):\n",
    "#     '''\n",
    "#     Find peaks and valleys of the data, excluding the first and last data points.\n",
    "\n",
    "#     Args:\n",
    "#         data: numpy.ndarray\n",
    "#             The input data array.\n",
    "#         pv_range: int\n",
    "#             The range within which peaks and valleys are detected.\n",
    "#         model_type: str\n",
    "#             Type of model, 'fft' or 'lstm'.\n",
    "            \n",
    "#         fft_processed_signal: numpy.ndarray \n",
    "#             The processed signal obtained by mixing the selected harmonics.\n",
    "#             shape: (number of windows, number of mixed harmonics, window_length)\n",
    "\n",
    "#         lstm_y: numpy.ndarray\n",
    "#             Processed signal obtained from predictions.\n",
    "#             shape = (number of windows, number of split y, length of y)\n",
    "#             flatten -> (number of windows, window_length)\n",
    "\n",
    "#     Returns:\n",
    "#         pv: numpy.ndarray\n",
    "#             An array of the same shape as `data`, where peaks are represented by 1,\n",
    "#             valleys are represented by -1, and other points are represented by 0.\n",
    "#             shape: (number of windows, window_length)\n",
    "#     Raises:\n",
    "#         None\n",
    "#     '''\n",
    "#     pv = np.zeros_like(data)\n",
    "#     for window in range(0, data.shape[0]):\n",
    "#         for harmonics in range(0, data.shape[1]):\n",
    "#             for l in range(0, data.shape[2]):\n",
    "#                 if l < pv_range:\n",
    "#                     if data[window, harmonics, l] == data[window, harmonics, :l+pv_range+1].max():\n",
    "#                         pv[window, harmonics, l] = 1\n",
    "#                     if data[window, harmonics, l] == data[window, harmonics, :l+pv_range+1].min():\n",
    "#                         pv[window, harmonics, l] = -1   \n",
    "#                 else:\n",
    "#                     if data[window, harmonics, l] == data[window, harmonics, l-pv_range:l+pv_range+1].max():\n",
    "#                         pv[window, harmonics, l] = 1   \n",
    "#                     if data[window, harmonics, l] == data[window, harmonics, l-pv_range:l+pv_range+1].min():\n",
    "#                         pv[window, harmonics, l] = -1\n",
    "#     return pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Postprocess:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def postprocess_lstm(self, predicted_y, scaler):\n",
    "        inversed_signal = self._inverse_transfer(predicted_y, scaler)\n",
    "        flatten_signal = self._flatten(inversed_signal)\n",
    "        return flatten_signal \n",
    "    \n",
    "    def postprocess_fft(self):\n",
    "        pass\n",
    "\n",
    "    def find_data_pv_function(self, data, pv_range, window_length):\n",
    "        '''\n",
    "        Find peaks and valleys of the data, excluding the first and last data points.\n",
    "\n",
    "        Args:\n",
    "            data: numpy.ndarray\n",
    "                The input data array.\n",
    "            pv_range: int\n",
    "                The range within which peaks and valleys are detected.\n",
    "            model_type: str\n",
    "                Type of model, 'fft' or 'lstm'.\n",
    "                \n",
    "            fft_processed_signal: numpy.ndarray \n",
    "                The processed signal obtained by mixing the selected harmonics.\n",
    "                shape: (number of windows, number of mixed harmonics, window_length)\n",
    "\n",
    "            lstm_y: numpy.ndarray\n",
    "                Processed signal obtained from predictions.\n",
    "                shape = (number of windows, number of split y, length of y)\n",
    "                flatten -> (number of windows, window_length)\n",
    "\n",
    "        Returns:\n",
    "            pv: numpy.ndarray\n",
    "                An array of the same shape as `data`, where peaks are represented by 1,\n",
    "                valleys are represented by -1, and other points are represented by 0.\n",
    "                shape: (number of windows, window_length)\n",
    "        Raises:\n",
    "            None\n",
    "        '''\n",
    "        pv = np.zeros_like(data)\n",
    "        if len(pv.shape) == 3:\n",
    "            for window in range(0, data.shape[0]):\n",
    "                for harmonics in range(0, data.shape[1]):\n",
    "                    pv[window, harmonics] = self._find_pv(data[window, harmonics], pv_range)\n",
    "        elif len(pv.shape) == 2:\n",
    "            for window in range(0, data.shape[0]):\n",
    "                pv[window] = self._find_pv(data[window], pv_range)\n",
    "        return pv\n",
    "    \n",
    "    def _find_pv(self, data, pv_range):\n",
    "        pv = np.zeros_like(data)\n",
    "        for l in range(0, data.shape[0]):\n",
    "            if l < pv_range:\n",
    "                if data[l] == data[:l+pv_range+1].max():\n",
    "                    pv[l] = 1\n",
    "                if data[l] == data[:l+pv_range+1].min():\n",
    "                    pv[l] = -1   \n",
    "            else:\n",
    "                if data[l] == data[l-pv_range:l+pv_range+1].max():\n",
    "                    pv[l] = 1   \n",
    "                if data[l] == data[l-pv_range:l+pv_range+1].min():\n",
    "                    pv[l] = -1\n",
    "        return pv\n",
    "    \n",
    "    def _inverse_transfer(self, predicted_y, scaler):\n",
    "        \"\"\"\n",
    "        flatten predictions.\n",
    "\n",
    "        Args:\n",
    "            predicted_y: numpy.ndarray\n",
    "                Predicted signal obtained from predictions.\n",
    "                shape = (number of windows, number of split y, length of y)\n",
    "\n",
    "        Returns:\n",
    "            processed_signal: numpy.ndarray\n",
    "                Processed signal flatten from predicted_y.\n",
    "                shape = (number of windows, 1, window_length)\n",
    "        \"\"\"\n",
    "\n",
    "        inversed_signal = np.zeros_like(predicted_y)\n",
    "        for window in range(0, predicted_y.shape[0]):\n",
    "            inversed_signal[window] = scaler.inverse_transform(predicted_y[window])\n",
    "        return inversed_signal\n",
    "    \n",
    "    def _flatten(self, inversed_signal):\n",
    "        \"\"\"\n",
    "        flatten predictions.\n",
    "\n",
    "        Args:\n",
    "            predicted_y: numpy.ndarray\n",
    "                Predicted signal obtained from predictions.\n",
    "                shape = (number of windows, number of split y, length of y)\n",
    "\n",
    "        Returns:\n",
    "            processed_signal: numpy.ndarray\n",
    "                Processed signal flatten from predicted_y.\n",
    "                shape = (number of windows, 1, window_length)\n",
    "        \"\"\"\n",
    "\n",
    "        flatten_signal = np.ndarray([inversed_signal.shape[0], inversed_signal.shape[1]*inversed_signal.shape[2]])\n",
    "        for window in range(0, inversed_signal.shape[0]):\n",
    "            flatten_signal[window] = inversed_signal[window].flatten()\n",
    "        return flatten_signal\n",
    "    \n",
    "    def _find_peak_lead(self, element, pv_train_data, pv_signal):\n",
    "        front = 'NULL'\n",
    "        back = 'NULL'\n",
    "        lead = None\n",
    "        forword = list(range(0, len(pv_signal)-element[0]))\n",
    "        backword = list(range(0, element[0]+1))\n",
    "        for i in forword:\n",
    "            if pv_train_data[element[0]+i] == 1:\n",
    "                front = i\n",
    "                break \n",
    "        for i in backword:\n",
    "            if pv_train_data[element[0]-i] == 1:\n",
    "                back = -i\n",
    "                break\n",
    "        if front == 'NULL' and back == 'NULL':\n",
    "            print('no answer')\n",
    "        elif front != 'NULL' and back == 'NULL':\n",
    "            lead = front\n",
    "        elif front == 'NULL' and back != 'NULL':\n",
    "            lead = back\n",
    "        elif front >= np.absolute(back):\n",
    "            lead = front\n",
    "        elif front < np.absolute(back):\n",
    "            lead = back\n",
    "        return lead\n",
    "\n",
    "    def _find_valley_lead(self, element, pv_train_data, pv_signal):\n",
    "        front = 'NULL'\n",
    "        back = 'NULL'\n",
    "        lead = None\n",
    "        forword = list(range(0, len(pv_signal)-element[0]))\n",
    "        backword = list(range(0, element[0]+1))\n",
    "        for i in forword:\n",
    "            if pv_train_data[element[0]+i] == -1:\n",
    "                front = i\n",
    "                break \n",
    "        for i in backword:\n",
    "            if pv_train_data[element[0]-i] == -1:\n",
    "                back = -i\n",
    "                break\n",
    "        if front == 'NULL' and back == 'NULL':\n",
    "            print('no answer')\n",
    "        elif front != 'NULL' and back == 'NULL':\n",
    "            lead = front\n",
    "        elif front == 'NULL' and back != 'NULL':\n",
    "            lead = back\n",
    "        elif front >= np.absolute(back):\n",
    "            lead = front\n",
    "        elif front < np.absolute(back):\n",
    "            lead = back\n",
    "        return lead\n",
    "    \n",
    "    def find_lead_function(self, pv_data, pv_signal):\n",
    "        lead_list = np.zeros_like(pv_signal)\n",
    "        for window in range(0, pv_signal.shape[0]):\n",
    "            for element in enumerate(pv_signal[window]):\n",
    "                if element[1] == 1:\n",
    "                    lead = self._find_peak_lead(element, pv_data[window], pv_signal[window])\n",
    "                    lead_list[window][element[0]] = lead\n",
    "                if element[1] == -1:\n",
    "                    lead = self._find_valley_lead(element, pv_data[window], pv_signal[window])\n",
    "                    lead_list[window][element[0]] = lead\n",
    "                else:\n",
    "                    lead_list[window][element[0]] = '-'\n",
    "        return lead_list\n",
    "    \n",
    "    # def get_first_lead_functaion(self, pv_signal, lead_test):\n",
    "    #     first_date = np.ndarray(pv_signal.shape[0])\n",
    "    #     lead = np.ndarray(pv_signal.shape[0])\n",
    "    #     pv = np.ndarray(pv_signal.shape[0])\n",
    "    #     for window in range(0, lead_test.shape[0]):\n",
    "    #         nonzero_indices = np.nonzero(lead_test[window])[0]\n",
    "    #         first_nonzero_index = nonzero_indices[0]\n",
    "    #         first_date[window] = first_nonzero_index\n",
    "    #         lead[window] = lead_test[window][first_nonzero_index]\n",
    "    #         pv[window] = pv_signal[window][first_nonzero_index]\n",
    "    #     return first_date, lead, pv\n",
    "\n",
    "    def get_first_lead_function(self, pv_signal, lead_test):\n",
    "        first_date = np.ndarray(pv_signal.shape[0])\n",
    "        lead = np.ndarray(pv_signal.shape[0])\n",
    "        pv = np.ndarray(pv_signal.shape[0])\n",
    "        for window in range(0, pv_signal.shape[0]):\n",
    "            # nonzero_indices = np.nonzero(lead_test[window])[0]\n",
    "            # first_nonzero_index = nonzero_indices[0]\n",
    "            for i in lead_test[window]:\n",
    "                if lead_test[window][i] != '-':\n",
    "                    first_date[window] = i\n",
    "                    lead[window] = lead_test[window][i]\n",
    "                    pv[window] = pv_signal[window][i]\n",
    "                    break\n",
    "        return first_date, lead, pv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = Postprocess()\n",
    "processed_signal = post.postprocess_lstm(lstm_processed_signal, scaler)\n",
    "pv_range = 2\n",
    "pv_train_data = post.find_data_pv_function(train_data, pv_range, window_length)\n",
    "pv_test_data = post.find_data_pv_function(test_data, pv_range, window_length)\n",
    "pv_signal = post.find_data_pv_function(processed_signal, pv_range, window_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 8))\n",
    "# plt.plot(processed_signal[0, 0])\n",
    "# for element in enumerate(pv_signal[0, 0]):\n",
    "#     if element[1] == 1:\n",
    "#         plt.plot(element[0], processed_signal[0, element[0]], '^')\n",
    "#     if element[1] == -1:\n",
    "#         plt.plot(element[0], processed_signal[0, element[0]], 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pv_train_data =   [0, 0, 0, 0, 1, 0, -1, 0, 0, 0, 0, 0, 0]\n",
    "# pv_signal = [0, 0, 1, 0, 0, -1, 0, 0, 0, 1, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_lead_function(pv_train_data, pv_signal):\n",
    "#     for element in enumerate(pv_signal):\n",
    "#         # print(element)\n",
    "#         if element[1] == 1:\n",
    "#             front = 'NULL'\n",
    "#             back = 'NULL'\n",
    "#             lead = None\n",
    "#             print(f'{element[0]} is a peak')\n",
    "#             forword = list(range(0, len(pv_signal)-element[0]))\n",
    "#             backword = list(range(0, element[0]+1))\n",
    "#             print('forword', forword)\n",
    "#             print('backword', backword)\n",
    "#             for i in forword:\n",
    "#                 if pv_train_data[element[0]+i] == 1:\n",
    "#                     front = i\n",
    "#                     break \n",
    "#             for i in backword:\n",
    "#                 if pv_train_data[element[0]-i] == 1:\n",
    "#                     back = -i\n",
    "#                     break\n",
    "#             if front == 'NULL' and back == 'NULL':\n",
    "#                 print('no answer')\n",
    "#             elif front != 'NULL' and back == 'NULL':\n",
    "#                 lead = front\n",
    "#             elif front == 'NULL' and back != 'NULL':\n",
    "#                 lead = back\n",
    "#             elif front >= np.absolute(back):\n",
    "#                 lead = front\n",
    "#             elif front < np.absolute(back):\n",
    "#                 lead = back\n",
    "            \n",
    "#             print(f'find peak {lead}')\n",
    "#             # print(f'find peak {back}')\n",
    "\n",
    "# find_lead_function(pv_train_data, pv_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_peak_lead(element, pv_train_data, pv_signal):\n",
    "    front = 'NULL'\n",
    "    back = 'NULL'\n",
    "    lead = None\n",
    "    forword = list(range(0, len(pv_signal)-element[0]))\n",
    "    backword = list(range(0, element[0]+1))\n",
    "    for i in forword:\n",
    "        if pv_train_data[element[0]+i] == 1:\n",
    "            front = i\n",
    "            break \n",
    "    for i in backword:\n",
    "        if pv_train_data[element[0]-i] == 1:\n",
    "            back = -i\n",
    "            break\n",
    "    if front == 'NULL' and back == 'NULL':\n",
    "        print('no answer')\n",
    "    elif front != 'NULL' and back == 'NULL':\n",
    "        lead = front\n",
    "    elif front == 'NULL' and back != 'NULL':\n",
    "        lead = back\n",
    "    elif front >= np.absolute(back):\n",
    "        lead = front\n",
    "    elif front < np.absolute(back):\n",
    "        lead = back\n",
    "    return lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_valley_lead(element, pv_train_data, pv_signal):\n",
    "    front = 'NULL'\n",
    "    back = 'NULL'\n",
    "    lead = None\n",
    "    forword = list(range(0, len(pv_signal)-element[0]))\n",
    "    backword = list(range(0, element[0]+1))\n",
    "    for i in forword:\n",
    "        if pv_train_data[element[0]+i] == -1:\n",
    "            front = i\n",
    "            break \n",
    "    for i in backword:\n",
    "        if pv_train_data[element[0]-i] == -1:\n",
    "            back = -i\n",
    "            break\n",
    "    if front == 'NULL' and back == 'NULL':\n",
    "        print('no answer')\n",
    "    elif front != 'NULL' and back == 'NULL':\n",
    "        lead = front\n",
    "    elif front == 'NULL' and back != 'NULL':\n",
    "        lead = back\n",
    "    elif front >= np.absolute(back):\n",
    "        lead = front\n",
    "    elif front < np.absolute(back):\n",
    "        lead = back\n",
    "    return lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lead_function(pv_data, pv_signal):\n",
    "    lead_list = {}\n",
    "    for window in range(0, pv_signal.shape[0]):\n",
    "        lead_list[window] = {}\n",
    "        for element in enumerate(pv_signal[window]):\n",
    "            if element[1] == 1:\n",
    "                lead = _find_peak_lead(element, pv_data[window], pv_signal[window])\n",
    "                lead_list[window][element[0]] = lead\n",
    "            if element[1] == -1:\n",
    "                lead = _find_valley_lead(element, pv_data[window], pv_signal[window])\n",
    "                lead_list[window][element[0]] = lead\n",
    "            else:\n",
    "                lead_list[window][element[0]] = '-'\n",
    "    return lead_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_train = find_lead_function(pv_train_data, pv_signal)\n",
    "lead_test = find_lead_function(pv_test_data, pv_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: '-',\n",
       "  1: 2,\n",
       "  2: '-',\n",
       "  3: '-',\n",
       "  4: '-',\n",
       "  5: '-',\n",
       "  6: '-',\n",
       "  7: -4,\n",
       "  8: '-',\n",
       "  9: '-',\n",
       "  10: '-',\n",
       "  11: '-',\n",
       "  12: '-',\n",
       "  13: '-',\n",
       "  14: '-',\n",
       "  15: '-',\n",
       "  16: '-',\n",
       "  17: '-',\n",
       "  18: '-',\n",
       "  19: '-',\n",
       "  20: '-',\n",
       "  21: 0,\n",
       "  22: '-',\n",
       "  23: '-',\n",
       "  24: '-',\n",
       "  25: '-',\n",
       "  26: -5,\n",
       "  27: '-',\n",
       "  28: '-',\n",
       "  29: '-'},\n",
       " 1: {0: 0,\n",
       "  1: '-',\n",
       "  2: '-',\n",
       "  3: '-',\n",
       "  4: -4,\n",
       "  5: '-',\n",
       "  6: '-',\n",
       "  7: '-',\n",
       "  8: '-',\n",
       "  9: '-',\n",
       "  10: 0,\n",
       "  11: '-',\n",
       "  12: '-',\n",
       "  13: '-',\n",
       "  14: '-',\n",
       "  15: '-',\n",
       "  16: '-',\n",
       "  17: 4,\n",
       "  18: '-',\n",
       "  19: '-',\n",
       "  20: '-',\n",
       "  21: '-',\n",
       "  22: 7,\n",
       "  23: '-',\n",
       "  24: '-',\n",
       "  25: '-',\n",
       "  26: '-',\n",
       "  27: '-',\n",
       "  28: '-',\n",
       "  29: 0},\n",
       " 2: {0: '-',\n",
       "  1: 4,\n",
       "  2: '-',\n",
       "  3: '-',\n",
       "  4: '-',\n",
       "  5: 0,\n",
       "  6: '-',\n",
       "  7: '-',\n",
       "  8: '-',\n",
       "  9: '-',\n",
       "  10: -5,\n",
       "  11: '-',\n",
       "  12: '-',\n",
       "  13: '-',\n",
       "  14: 11,\n",
       "  15: '-',\n",
       "  16: '-',\n",
       "  17: '-',\n",
       "  18: '-',\n",
       "  19: -7,\n",
       "  20: '-',\n",
       "  21: '-',\n",
       "  22: '-',\n",
       "  23: '-',\n",
       "  24: '-',\n",
       "  25: '-',\n",
       "  26: '-',\n",
       "  27: '-',\n",
       "  28: '-',\n",
       "  29: '-'}}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lead_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: '-',\n",
       "  1: 0,\n",
       "  2: '-',\n",
       "  3: '-',\n",
       "  4: '-',\n",
       "  5: '-',\n",
       "  6: '-',\n",
       "  7: 9,\n",
       "  8: '-',\n",
       "  9: '-',\n",
       "  10: '-',\n",
       "  11: '-',\n",
       "  12: '-',\n",
       "  13: '-',\n",
       "  14: '-',\n",
       "  15: '-',\n",
       "  16: '-',\n",
       "  17: '-',\n",
       "  18: '-',\n",
       "  19: '-',\n",
       "  20: '-',\n",
       "  21: 4,\n",
       "  22: '-',\n",
       "  23: '-',\n",
       "  24: '-',\n",
       "  25: '-',\n",
       "  26: -1,\n",
       "  27: '-',\n",
       "  28: '-',\n",
       "  29: '-'},\n",
       " 1: {0: 1,\n",
       "  1: '-',\n",
       "  2: '-',\n",
       "  3: '-',\n",
       "  4: 6,\n",
       "  5: '-',\n",
       "  6: '-',\n",
       "  7: '-',\n",
       "  8: '-',\n",
       "  9: '-',\n",
       "  10: 0,\n",
       "  11: '-',\n",
       "  12: '-',\n",
       "  13: '-',\n",
       "  14: '-',\n",
       "  15: '-',\n",
       "  16: '-',\n",
       "  17: 5,\n",
       "  18: '-',\n",
       "  19: '-',\n",
       "  20: '-',\n",
       "  21: '-',\n",
       "  22: 0,\n",
       "  23: '-',\n",
       "  24: '-',\n",
       "  25: '-',\n",
       "  26: '-',\n",
       "  27: '-',\n",
       "  28: '-',\n",
       "  29: -7},\n",
       " 2: {0: '-',\n",
       "  1: 2,\n",
       "  2: '-',\n",
       "  3: '-',\n",
       "  4: '-',\n",
       "  5: 6,\n",
       "  6: '-',\n",
       "  7: '-',\n",
       "  8: '-',\n",
       "  9: '-',\n",
       "  10: -7,\n",
       "  11: '-',\n",
       "  12: '-',\n",
       "  13: '-',\n",
       "  14: -3,\n",
       "  15: '-',\n",
       "  16: '-',\n",
       "  17: '-',\n",
       "  18: '-',\n",
       "  19: -8,\n",
       "  20: '-',\n",
       "  21: '-',\n",
       "  22: '-',\n",
       "  23: '-',\n",
       "  24: '-',\n",
       "  25: '-',\n",
       "  26: '-',\n",
       "  27: '-',\n",
       "  28: '-',\n",
       "  29: '-'}}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lead_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., -1.,  1.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  1.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  1.,  0., -1.,  0.,  0.,  1.,  0.,\n",
       "        -1.,  0.,  0.,  1.],\n",
       "       [-1.,  0.,  1.,  0., -1.,  0.,  0.,  1.,  0.,  0., -1.,  0.,  1.,\n",
       "         0.,  0.,  0.,  0., -1.,  0.,  1.,  0.,  0., -1.,  0.,  0.,  0.,\n",
       "         0.,  1.,  0., -1.],\n",
       "       [ 0., -1.,  0.,  0.,  1., -1.,  0.,  0.,  0.,  0., -1.,  1.,  0.,\n",
       "         0., -1.,  0.,  1.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pv_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_lead_function(pv_signal, lead_test):\n",
    "    first_date = np.ndarray(pv_signal.shape[0])\n",
    "    lead = np.ndarray(pv_signal.shape[0])\n",
    "    pv = np.ndarray(pv_signal.shape[0])\n",
    "    for window in range(0, pv_signal.shape[0]):\n",
    "        # nonzero_indices = np.nonzero(lead_test[window])[0]\n",
    "        # first_nonzero_index = nonzero_indices[0]\n",
    "        for i in lead_test[window]:\n",
    "            if lead_test[window][i] != '-':\n",
    "                first_date[window] = i\n",
    "                lead[window] = lead_test[window][i]\n",
    "                pv[window] = pv_signal[window][i]\n",
    "                break\n",
    "    return first_date, lead, pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_date, lead, pv = get_first_lead_function(pv_signal, lead_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1.])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2.])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1.])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 30, 30)\n",
      "[[[  9.38079178   8.43322849   7.11709265 ...   9.68853424  10.02246679\n",
      "     9.91836946]\n",
      "  [  9.38079178   8.43322849   7.11709265 ...   9.68853424  10.02246679\n",
      "     9.91836946]\n",
      "  [  9.38079178   8.43322849   7.11709265 ...   9.68853424  10.02246679\n",
      "     9.91836946]\n",
      "  ...\n",
      "  [  9.38079178   8.43322849   7.11709265 ...   9.68853424  10.02246679\n",
      "     9.91836946]\n",
      "  [  9.38079178   8.43322849   7.11709265 ...   9.68853424  10.02246679\n",
      "     9.91836946]\n",
      "  [  9.38079178   8.43322849   7.11709265 ...   9.68853424  10.02246679\n",
      "     9.91836946]]\n",
      "\n",
      " [[-40.68542609 -45.49623033 -48.31863098 ... -16.80112665 -26.01734141\n",
      "   -34.0964735 ]\n",
      "  [-40.68542609 -45.49623033 -48.31863098 ... -16.80112665 -26.01734141\n",
      "   -34.0964735 ]\n",
      "  [-40.68542609 -45.49623033 -48.31863098 ... -16.80112665 -26.01734141\n",
      "   -34.0964735 ]\n",
      "  ...\n",
      "  [-40.68542609 -45.49623033 -48.31863098 ... -16.80112665 -26.01734141\n",
      "   -34.0964735 ]\n",
      "  [-40.68542609 -45.49623033 -48.31863098 ... -16.80112665 -26.01734141\n",
      "   -34.0964735 ]\n",
      "  [-40.68542609 -45.49623033 -48.31863098 ... -16.80112665 -26.01734141\n",
      "   -34.0964735 ]]\n",
      "\n",
      " [[ -8.72258036 -11.34563795 -13.47283672 ...   0.89777638  -2.46411062\n",
      "    -5.71830416]\n",
      "  [ -8.72258036 -11.34563795 -13.47283672 ...   0.89777638  -2.46411062\n",
      "    -5.71830416]\n",
      "  [ -8.72258036 -11.34563795 -13.47283672 ...   0.89777638  -2.46411062\n",
      "    -5.71830416]\n",
      "  ...\n",
      "  [ -8.72258036 -11.34563795 -13.47283672 ...   0.89777638  -2.46411062\n",
      "    -5.71830416]\n",
      "  [ -8.72258036 -11.34563795 -13.47283672 ...   0.89777638  -2.46411062\n",
      "    -5.71830416]\n",
      "  [ -8.72258036 -11.34563795 -13.47283672 ...   0.89777638  -2.46411062\n",
      "    -5.71830416]]]\n",
      "(3, 30, 30)\n"
     ]
    }
   ],
   "source": [
    "print(mixed_train_harm.shape)\n",
    "print(mixed_test_harm)\n",
    "print(mixed_test_harm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  9.38079178,   8.43322849,   7.11709265, ...,   9.68853424,\n",
       "          10.02246679,   9.91836946],\n",
       "        [  9.38079178,   8.43322849,   7.11709265, ...,   9.68853424,\n",
       "          10.02246679,   9.91836946],\n",
       "        [  9.38079178,   8.43322849,   7.11709265, ...,   9.68853424,\n",
       "          10.02246679,   9.91836946],\n",
       "        ...,\n",
       "        [  9.38079178,   8.43322849,   7.11709265, ...,   9.68853424,\n",
       "          10.02246679,   9.91836946],\n",
       "        [  9.38079178,   8.43322849,   7.11709265, ...,   9.68853424,\n",
       "          10.02246679,   9.91836946],\n",
       "        [  9.38079178,   8.43322849,   7.11709265, ...,   9.68853424,\n",
       "          10.02246679,   9.91836946]],\n",
       "\n",
       "       [[-40.68542609, -45.49623033, -48.31863098, ..., -16.80112665,\n",
       "         -26.01734141, -34.0964735 ],\n",
       "        [-40.68542609, -45.49623033, -48.31863098, ..., -16.80112665,\n",
       "         -26.01734141, -34.0964735 ],\n",
       "        [-40.68542609, -45.49623033, -48.31863098, ..., -16.80112665,\n",
       "         -26.01734141, -34.0964735 ],\n",
       "        ...,\n",
       "        [-40.68542609, -45.49623033, -48.31863098, ..., -16.80112665,\n",
       "         -26.01734141, -34.0964735 ],\n",
       "        [-40.68542609, -45.49623033, -48.31863098, ..., -16.80112665,\n",
       "         -26.01734141, -34.0964735 ],\n",
       "        [-40.68542609, -45.49623033, -48.31863098, ..., -16.80112665,\n",
       "         -26.01734141, -34.0964735 ]],\n",
       "\n",
       "       [[ -8.72258036, -11.34563795, -13.47283672, ...,   0.89777638,\n",
       "          -2.46411062,  -5.71830416],\n",
       "        [ -8.72258036, -11.34563795, -13.47283672, ...,   0.89777638,\n",
       "          -2.46411062,  -5.71830416],\n",
       "        [ -8.72258036, -11.34563795, -13.47283672, ...,   0.89777638,\n",
       "          -2.46411062,  -5.71830416],\n",
       "        ...,\n",
       "        [ -8.72258036, -11.34563795, -13.47283672, ...,   0.89777638,\n",
       "          -2.46411062,  -5.71830416],\n",
       "        [ -8.72258036, -11.34563795, -13.47283672, ...,   0.89777638,\n",
       "          -2.46411062,  -5.71830416],\n",
       "        [ -8.72258036, -11.34563795, -13.47283672, ...,   0.89777638,\n",
       "          -2.46411062,  -5.71830416]]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_train_harm\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
